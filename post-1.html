<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OpenAI Sora 2 Update - The Corporate AI Ledger</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <header>
        <h1>The Corporate AI Ledger</h1>
        <nav>
            <a href="index.html">Home</a> |
            <a href="about.html">About</a>
        </nav>
    </header>

    <main>
        <article>
            <h2>OpenAI Sora 2 Hits 25-Second Mark and Integrated "Talkies"</h2>
            <p class="date">January 20, 2026</p>

            <p>OpenAI has officially rolled out Sora 2, a massive update to their flagship video model. The most significant leap is the extension of clip length from the original 6–10 seconds to a full 25 seconds for Pro users. More importantly, Sora has finally moved past the "silent movie" era by introducing synchronized audio generation.</p>

            <h3>The Details</h3>
            <p>The new model generates high-fidelity video and audio simultaneously. This includes realistic lip-syncing for characters and "environmental Foley,” meaning if a character drops a glass on screen, the sound of shattering glass occurs at the exact frame of impact. OpenAI also introduced a "Storyboard" tool, allowing users to piece together multiple 25-second scenes into a coherent narrative thread.</p>

            <h3>My Take</h3>
            <p>The shift from short silent clips to long synchronized segments transforms AI video from a social media gimmick to an actual pre-visualization tool for filmmakers. The ability to sustain a story for 30 seconds without "hallucination drift" brings us ever closer to an AI-generated short film that requires no inordinate amount of outside editing.</p>
        </article>
    </main>

    <footer>
        <p>&copy; 2026 Chase</p>
    </footer>
</body>
</html>
